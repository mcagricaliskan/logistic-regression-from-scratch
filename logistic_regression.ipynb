{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Creating Logistic Regression \n",
    "This class include sigmoid, relu, binary cross entropy and mean squared error implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01) -> None:\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = 1e-15\n",
    "        self.cost_track = {}\n",
    "\n",
    "    def sigmoid(self, a):\n",
    "        return 1 / (1 + np.exp(-a))\n",
    "\n",
    "    def feed_forward(self):\n",
    "        return self.sigmoid(\n",
    "            np.dot(self.x_train, self.w) + self.b\n",
    "        )\n",
    "\n",
    "    def binary_crossentropy(self, y, y_pred): # also named as log loss \n",
    "        # clip because preventing log(0) error\n",
    "        y_pred = np.clip(y_pred, self.epsilon, 1 - 1e-3)\n",
    "        return - (1 / self.m) * np.sum((y * np.log(y_pred)) + ((1 - y) * np.log(1 - y_pred)))\n",
    "\n",
    "    def back_propagation(self, y_pred):\n",
    "        cost = self.binary_crossentropy(self.y_train, y_pred)\n",
    "        dw = (1 / self.m) * np.dot(self.x_train.T, (y_pred - self.y_train))\n",
    "        db = (1 / self.m) * np.sum(y_pred - self.y_train)\n",
    "\n",
    "        # updating weights and bias\n",
    "        self.w = self.w - self.learning_rate * dw\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def save(self, file_path):\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump({\"w\": self.w, \"b\": self.b}, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load(self, file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            temp = pickle.load(f)\n",
    "\n",
    "        self.w = temp[\"w\"]\n",
    "        self.b = temp[\"b\"]\n",
    "        del temp\n",
    "\n",
    "    def initialize_paramters(self):\n",
    "        (self.m, feature_count) = self.x_train.shape[0], self.x_train.shape[1]\n",
    "        # initialize weights and bias\n",
    "        self.w = np.zeros((feature_count, 1))\n",
    "        self.b = np.zeros((1, 1))\n",
    "\n",
    "    def calculate_accuracy(self, y_pred, y):\n",
    "        return  ((y_pred > 0.5) == y).sum() / self.m\n",
    "\n",
    "    def fit(self, x_train, y_train, epoch, learning_rate=0.001, print_cost=True):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        self.initialize_paramters()\n",
    "        \n",
    "        for e in range(1, epoch + 1):\n",
    "            y_pred = self.feed_forward()\n",
    "            cost = self.back_propagation(y_pred)\n",
    "\n",
    "            if e % 100 == 0:\n",
    "                print(f\"Epoch: {e}, train_loss: {np.squeeze(cost)}, train_accuracy: {self.calculate_accuracy(y_pred, self.y_train)}\")\n",
    "                self.cost_track.setdefault(e, cost)\n",
    "\n",
    "        del self.x_train\n",
    "        del self.y_train\n",
    "\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        # @TODO plot and classification report\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        # @TODO single data prediction\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"framingham.csv\").dropna()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"TenYearCHD\", axis=1).values\n",
    "y = df[\"TenYearCHD\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model object\n",
    "\n",
    "lrm_hearth = LogisticRegression()\n",
    "lrm_hearth.fit(x_train=x_train, y_train=y_train, epoch=1000, learning_rate=0.000000015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrm.save(\"./test.pckl\")\n",
    "# lrm.load(\"./test.pckl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Diabetics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetics_df = pd.read_csv(\"diabetes2.csv\")\n",
    "\n",
    "diabetics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetics_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diabetics_df.drop(\"Outcome\", axis=1).values\n",
    "y = diabetics_df[\"Outcome\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lrm_diabet = LogisticRegression()\n",
    "lrm_diabet.fit(x_train=x_train, y_train=y_train, epoch=1000, learning_rate=0.000000015)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a25f35f9ace4a42c6c8989cf1c3c16907d22c5430b3731c3e7f70665c744376c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
